{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from lib.Data import DesignDataset\n",
    "DATA_ROOT=\"F:\\\\dise\\\\flask-dise\\\\static\\\\img\\\\DataSet\"\n",
    "VEC_ROOT = \"F:\\\\dise\\\\flask-dise\\\\static\\\\feature\\\\VGG16\\\\VGG16\\\\DataSet\"\n",
    "dataset = DesignDataset(root=DATA_ROOT, vector_root=VEC_ROOT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3.26477085e-08, 3.41555301e-06, 7.06066938e-09, 2.86523960e-09,\n       3.69101940e-08, 7.86590704e-07, 8.99535877e-08, 2.15072902e-07,\n       1.41474217e-07, 6.10425621e-09, 2.28197521e-07, 5.21993542e-08,\n       2.79002677e-07, 1.11543024e-07, 6.07387449e-07, 2.45306325e-07,\n       3.65705333e-08, 2.92636116e-07, 3.10634675e-07, 1.37748160e-07,\n       6.04340400e-08, 1.85583016e-08, 3.21498881e-08, 1.39647618e-08,\n       1.07780338e-07, 6.63393564e-07, 2.91317662e-07, 3.44640313e-07,\n       3.86011948e-07, 1.91099705e-08, 4.61313583e-08, 1.38221683e-08,\n       4.72433754e-07, 1.09072666e-07, 4.79857022e-07, 1.14247064e-06,\n       5.61415391e-07, 2.24732207e-06, 2.08331983e-07, 1.59624403e-08,\n       1.00751638e-08, 9.19933854e-08, 6.49522391e-08, 1.54691662e-07,\n       8.39709600e-08, 8.05230286e-07, 1.22115225e-08, 2.23117027e-07,\n       1.37870968e-08, 5.74659339e-07, 4.00468352e-08, 2.64549726e-07,\n       8.46169712e-08, 4.02149283e-08, 9.66855751e-08, 9.54971480e-09,\n       1.75141579e-07, 2.25181097e-07, 2.54853916e-08, 1.02387849e-08,\n       7.89205501e-07, 7.95595980e-08, 4.72389644e-07, 4.12402699e-08,\n       3.41045236e-08, 2.77707528e-07, 6.98458280e-07, 1.80513936e-07,\n       4.90168588e-07, 1.72953526e-06, 7.88736330e-08, 2.29928986e-07,\n       3.99966886e-08, 2.17656589e-06, 3.15673333e-07, 1.00677354e-07,\n       6.36006916e-07, 7.50129288e-07, 1.94371205e-06, 4.64536879e-06,\n       7.10219638e-07, 8.43509227e-08, 4.12021222e-07, 5.16201737e-07,\n       6.44651891e-07, 1.75982905e-07, 3.70171961e-07, 3.70110911e-07,\n       3.75909195e-07, 2.99300922e-08, 1.17326522e-07, 3.35540129e-08,\n       4.74759538e-08, 1.35067948e-08, 4.03082296e-08, 2.35651889e-08,\n       5.53499220e-08, 5.57362902e-08, 1.26361414e-07, 3.32244490e-08,\n       1.28206281e-08, 2.05136118e-07, 1.12594037e-07, 3.21377968e-07,\n       1.10593113e-07, 3.11030091e-09, 2.30475194e-07, 2.34225894e-07,\n       3.91698336e-07, 2.12048417e-06, 3.03596295e-07, 1.69589043e-06,\n       5.98839961e-07, 6.41458598e-07, 3.04261789e-07, 2.30048286e-07,\n       9.92994387e-07, 2.09005606e-07, 7.61959484e-07, 2.27081230e-07,\n       7.73348106e-08, 4.20699280e-07, 2.04648904e-06, 1.36727488e-06,\n       1.17508660e-06, 3.26260590e-07, 2.13278128e-07, 1.17638670e-07,\n       1.04993831e-07, 9.59942437e-09, 4.87011995e-08, 1.54957807e-08,\n       4.48167263e-08, 2.79687207e-08, 1.04155312e-07, 4.89891718e-08,\n       9.84682984e-08, 3.28236126e-07, 3.95374222e-08, 9.32757516e-08,\n       5.58239265e-07, 1.74885557e-07, 1.53170546e-07, 5.27458042e-08,\n       1.14103882e-08, 3.98403728e-08, 7.47840234e-10, 3.63759356e-09,\n       3.55673428e-08, 1.00216919e-08, 2.03807495e-08, 3.47482342e-06,\n       7.25046689e-08, 5.02284820e-07, 4.58708371e-07, 7.95017684e-07,\n       5.51067785e-07, 1.25629367e-06, 1.04644118e-06, 1.10619317e-06,\n       1.09436712e-07, 1.28253498e-06, 1.74838272e-06, 2.08345591e-06,\n       3.96565440e-07, 3.81746247e-07, 1.22655564e-07, 3.66844603e-07,\n       2.45220622e-06, 1.27676813e-07, 2.33752161e-07, 5.10052132e-07,\n       1.91071720e-07, 1.24905114e-07, 5.51163964e-07, 4.06925608e-07,\n       6.52231193e-08, 3.72604518e-07, 4.24923456e-07, 3.72782756e-06,\n       1.28753641e-06, 1.14237707e-06, 2.74698255e-06, 6.09583253e-07,\n       1.13317026e-06, 4.35993070e-06, 4.03774129e-06, 1.32838181e-06,\n       5.02669593e-07, 5.59252783e-07, 2.84242446e-07, 1.15010607e-05,\n       3.06977927e-05, 1.88700676e-06, 1.18701493e-07, 1.77952359e-06,\n       7.10664779e-07, 7.12352346e-07, 2.67448604e-06, 4.27037412e-06,\n       1.37260599e-07, 9.68632412e-06, 1.25279882e-06, 3.12222596e-06,\n       5.24792995e-07, 2.47155810e-07, 3.52202704e-07, 3.07043507e-07,\n       1.28013505e-06, 6.10561870e-07, 6.30027955e-07, 8.22600123e-06,\n       5.10522227e-07, 5.71072746e-07, 7.74160128e-07, 8.15612225e-07,\n       9.71243139e-07, 3.16937872e-07, 2.26211387e-06, 7.63131084e-07,\n       1.51927190e-06, 2.58043173e-07, 2.23577302e-07, 3.97430767e-06,\n       1.32595665e-06, 1.34964307e-06, 4.15854714e-07, 8.14935788e-07,\n       2.06344367e-07, 1.82760260e-07, 1.57326474e-06, 5.10055031e-07,\n       5.74854482e-07, 2.46116173e-07, 6.33042987e-07, 1.89946036e-07,\n       6.76420427e-07, 1.93545497e-06, 4.97466146e-07, 2.00477245e-07,\n       3.71729271e-07, 7.43542500e-07, 1.49396715e-06, 1.39320935e-06,\n       5.89611737e-08, 1.51689312e-06, 1.73272724e-07, 1.75687603e-07,\n       2.15470138e-07, 5.13112326e-08, 7.25963162e-07, 8.63775654e-07,\n       4.62063241e-07, 2.62010167e-06, 2.19991125e-06, 2.29834484e-07,\n       7.63810704e-08, 4.93496486e-07, 1.94518719e-07, 6.68284258e-07,\n       3.71279498e-06, 2.87312020e-07, 1.59427395e-06, 1.16049955e-06,\n       5.36620064e-07, 1.78218829e-06, 1.48660240e-06, 3.38560511e-07,\n       1.11228655e-06, 6.30892245e-08, 7.10071646e-08, 1.27722956e-07,\n       4.38765824e-07, 6.49630522e-07, 1.87819765e-07, 2.93287627e-07,\n       1.48734387e-06, 9.67862661e-07, 6.70026665e-08, 4.72725361e-07,\n       3.06601635e-07, 1.17801517e-06, 2.60836418e-06, 1.40630136e-05,\n       2.23589905e-05, 1.58387797e-06, 1.66791196e-07, 3.70512822e-07,\n       7.83693736e-07, 1.22899579e-07, 2.96747089e-07, 2.88923843e-07,\n       6.58919305e-07, 1.54322186e-06, 6.60497278e-07, 1.28594408e-07,\n       2.23859558e-07, 6.15711286e-08, 4.91485537e-08, 6.27822843e-08,\n       1.07353856e-06, 6.64593585e-07, 4.18567697e-06, 1.65265715e-06,\n       1.34918889e-06, 1.06981020e-06, 1.32879745e-06, 7.83178905e-07,\n       1.00466927e-07, 5.52333120e-07, 2.40247005e-06, 1.39373483e-07,\n       1.03308309e-07, 2.27061534e-07, 3.32065838e-06, 3.65808384e-09,\n       2.67101314e-07, 8.46965662e-08, 1.41915024e-07, 9.28317320e-07,\n       2.22093846e-08, 1.22251862e-07, 2.91594489e-07, 5.68518260e-07,\n       2.01494537e-08, 4.89479646e-07, 1.39077386e-07, 1.49953974e-06,\n       1.69339601e-05, 7.04961209e-08, 5.29439376e-07, 2.90887897e-07,\n       5.14725514e-07, 8.02100203e-07, 1.90643092e-07, 4.65150151e-07,\n       3.65741606e-08, 1.98161933e-06, 4.01297839e-05, 1.16814064e-07,\n       5.71653302e-08, 1.28271922e-05, 1.06600892e-05, 7.59618899e-07,\n       7.78811327e-09, 4.02935711e-07, 7.15531257e-07, 8.13286292e-08,\n       1.22481456e-08, 1.14120368e-07, 1.71641375e-07, 3.59793937e-08,\n       3.05469072e-08, 4.57381510e-08, 1.10617111e-06, 1.96884486e-07,\n       3.02245724e-07, 3.24061062e-07, 1.70048736e-07, 6.00402757e-07,\n       1.09725988e-07, 2.43648060e-06, 1.11433302e-07, 7.67759104e-07,\n       9.19081078e-09, 1.23010736e-07, 1.25476216e-08, 4.01137328e-08,\n       1.26358346e-08, 3.43302098e-08, 3.78399427e-08, 1.32061530e-07,\n       1.19753139e-07, 5.13663394e-07, 2.66775203e-07, 1.36713014e-08,\n       3.06836512e-07, 3.73215812e-07, 1.21680984e-07, 7.35271541e-08,\n       1.34203901e-07, 7.50212550e-08, 8.46285815e-08, 1.48614504e-07,\n       1.91679383e-08, 9.58730197e-07, 9.18874719e-08, 1.09947154e-08,\n       2.12191171e-08, 3.13079518e-08, 5.50813688e-08, 1.42808290e-08,\n       1.19721574e-06, 1.11870285e-07, 6.15555962e-09, 6.68825280e-08,\n       2.28505357e-08, 2.76453164e-07, 3.04406480e-04, 2.40218833e-06,\n       1.32450066e-06, 3.86875072e-05, 2.52172026e-06, 2.12532157e-07,\n       1.33832421e-08, 1.59029696e-06, 4.53173071e-02, 6.84333514e-08,\n       2.88774107e-08, 1.85543031e-04, 2.03492891e-06, 1.58299154e-04,\n       2.22675510e-07, 1.02378192e-06, 1.56161914e-05, 9.57429052e-07,\n       6.63576074e-08, 4.95444283e-06, 6.47287061e-06, 5.34654191e-06,\n       4.69040560e-06, 2.87526518e-06, 1.14844006e-07, 3.97625428e-07,\n       1.58420193e-07, 1.46439220e-06, 2.56055355e-05, 1.85834153e-06,\n       1.94599608e-07, 5.92290121e-07, 1.42187318e-07, 7.42714064e-07,\n       5.88535931e-06, 9.19444005e-07, 2.61354471e-05, 1.10749261e-06,\n       2.60292580e-07, 3.39864499e-07, 2.05230833e-07, 1.64922483e-06,\n       2.17301499e-06, 2.86048078e-07, 2.77165655e-05, 3.31416813e-05,\n       3.87079155e-07, 1.22271558e-07, 1.07756560e-03, 1.24766007e-06,\n       1.70616149e-05, 3.14668227e-07, 2.62661128e-08, 7.82474162e-05,\n       5.88248031e-06, 3.22415464e-04, 8.10247820e-06, 1.06078973e-04,\n       9.80753430e-06, 5.71471310e-06, 1.69388950e-04, 4.64372306e-07,\n       5.08027966e-08, 4.59868279e-05, 1.84488226e-06, 1.02054692e-07,\n       1.13187969e-04, 1.24544647e-06, 1.23168338e-08, 5.38399085e-08,\n       1.83424402e-06, 2.39797896e-06, 2.79181022e-05, 1.29562935e-07,\n       1.32658773e-08, 4.07806681e-07, 4.59471994e-05, 1.88321163e-08,\n       1.31649967e-05, 3.74399565e-06, 4.46716012e-06, 6.67699362e-09,\n       4.07754612e-07, 1.24713668e-04, 3.02010767e-06, 1.48567615e-05,\n       1.06663878e-08, 1.52005009e-06, 6.02237014e-06, 4.48817190e-07,\n       1.91775835e-05, 4.72054097e-07, 1.37014467e-05, 5.66118217e-07,\n       1.38574513e-03, 3.67830769e-04, 4.76653004e-05, 3.49010588e-05,\n       4.39245669e-05, 1.10335229e-03, 3.38165228e-05, 8.28083444e-07,\n       4.40386088e-07, 1.39886952e-05, 1.12604403e-06, 1.61562468e-07,\n       1.28057457e-06, 1.11208067e-06, 2.00001959e-05, 4.20069881e-07,\n       7.65488039e-06, 9.48459819e-06, 9.56543289e-08, 4.75870117e-08,\n       4.71768544e-06, 2.30583032e-06, 1.17701624e-07, 2.73703876e-07,\n       6.55373196e-06, 2.21627965e-06, 1.02221264e-07, 7.25807058e-06,\n       9.16142017e-06, 3.80737333e-07, 9.01084434e-07, 2.02237675e-06,\n       7.31672662e-06, 7.72946596e-09, 1.92989246e-04, 2.57397751e-05,\n       1.08555719e-06, 9.85284714e-07, 2.98580790e-06, 1.33202127e-06,\n       6.96521311e-05, 2.19662288e-05, 5.55797044e-08, 2.56826791e-08,\n       2.06386886e-07, 1.94079007e-07, 6.97603216e-04, 1.33046939e-03,\n       7.61922865e-06, 5.32502236e-06, 4.02069918e-06, 2.01785397e-07,\n       2.14512028e-07, 2.73648698e-06, 2.54172369e-06, 6.05093646e-08,\n       8.76036574e-06, 1.34634250e-03, 1.73043766e-08, 2.98107498e-05,\n       1.80168263e-05, 2.57637221e-05, 2.58719695e-08, 7.66173400e-07,\n       2.57421844e-03, 4.93494156e-07, 8.90761930e-06, 3.02464150e-06,\n       3.53670885e-07, 1.28861859e-06, 1.62659690e-05, 2.01371427e-06,\n       4.27224986e-05, 2.34068040e-07, 1.64246148e-06, 3.46843166e-07,\n       3.00464058e-06, 1.29873456e-07, 1.38149471e-06, 5.10238181e-08,\n       5.49494189e-06, 6.16707965e-08, 4.70591459e-07, 8.35900025e-08,\n       1.50584390e-06, 2.01941948e-05, 1.68763719e-07, 3.42743842e-05,\n       5.55533916e-07, 5.57580861e-08, 5.79152697e-07, 6.46223089e-06,\n       4.64975856e-05, 1.61614480e-06, 5.31536898e-07, 2.99668500e-06,\n       8.69840369e-06, 6.39761481e-07, 3.16132900e-06, 2.23624142e-04,\n       1.18859862e-05, 7.57620364e-06, 3.99689316e-06, 4.82812311e-07,\n       8.18045805e-07, 2.82964379e-06, 4.59752755e-06, 6.51999653e-05,\n       2.67998184e-05, 1.28755346e-06, 8.05983618e-08, 5.98754809e-07,\n       3.67955113e-06, 6.53710515e-07, 1.47743935e-06, 6.87341571e-06,\n       8.49847675e-06, 6.38022186e-08, 6.46063518e-06, 4.15549316e-02,\n       1.67029725e-06, 2.58849886e-05, 6.29508168e-06, 1.72022865e-07,\n       9.85665224e-07, 5.00099532e-07, 7.39916572e-07, 1.30560526e-04,\n       2.40884474e-05, 2.50046554e-07, 3.88188568e-07, 3.44437717e-06,\n       1.15168164e-04, 5.63544695e-08, 9.19029026e-06, 2.86896515e-08,\n       3.51357613e-07, 8.76119714e-07, 5.60966633e-08, 5.26290535e-07,\n       9.90365152e-07, 4.41056727e-06, 8.60641194e-07, 2.04797780e-05,\n       4.61698946e-05, 5.65466098e-06, 1.91548096e-07, 1.97197167e-07,\n       3.43743392e-04, 1.91414074e-05, 6.16554553e-06, 3.14434546e-05,\n       6.61533295e-06, 2.99530058e-07, 1.80555799e-03, 6.09681265e-08,\n       1.28945640e-05, 9.88048214e-07, 5.00468786e-07, 9.86505029e-07,\n       2.10765506e-06, 7.57281455e-08, 1.31041574e-07, 4.89827244e-06,\n       8.24752320e-08, 3.96519681e-07, 3.02087265e-05, 1.05126651e-06,\n       3.86840782e-07, 1.22878717e-07, 6.35309425e-06, 5.35803963e-04,\n       2.99276817e-05, 2.04028339e-07, 2.14558071e-07, 1.44184287e-06,\n       1.42597361e-04, 8.65333959e-07, 2.08557211e-07, 2.21716743e-08,\n       7.64646018e-08, 1.83547854e-05, 8.55921680e-05, 6.46770602e-08,\n       1.40660163e-07, 8.54272275e-06, 4.13845697e-07, 8.33110607e-06,\n       1.18450509e-06, 2.51420875e-06, 9.35637854e-06, 2.36906908e-05,\n       3.83293773e-05, 9.79869341e-09, 2.81767228e-07, 2.60431785e-04,\n       1.61028547e-05, 1.14133593e-06, 4.33076502e-06, 1.55482496e-07,\n       6.30006907e-05, 2.68411526e-07, 7.73015131e-07, 4.00541376e-06,\n       1.20923605e-05, 7.07286802e-07, 5.63416921e-04, 3.42003332e-05,\n       1.16336796e-05, 2.91238223e-07, 4.87228704e-07, 6.58885710e-06,\n       6.85616158e-07, 1.24408430e-07, 9.52920061e-07, 2.98467910e-07,\n       1.32530886e-05, 8.25123352e-05, 1.62344477e-05, 1.27498442e-05,\n       6.23915730e-06, 2.46011979e-07, 7.20184516e-07, 4.27866144e-06,\n       2.60342108e-06, 2.02603285e-08, 5.11119936e-07, 1.16466235e-05,\n       1.47421770e-06, 5.66026196e-04, 1.13174360e-06, 6.61401145e-07,\n       1.92853904e-07, 8.16184547e-06, 1.37412326e-06, 9.51695881e-07,\n       1.28001420e-06, 2.46742475e-05, 1.07778033e-06, 3.86301963e-06,\n       1.86697022e-07, 3.77579880e-07, 1.21739120e-07, 2.77658273e-05,\n       1.85569825e-05, 6.03026365e-07, 1.06751816e-06, 1.59910783e-07,\n       5.54599126e-07, 9.98087227e-01, 2.15493060e-06, 2.61662677e-07,\n       1.52550982e-07, 3.52866721e-07, 3.75198806e-06, 5.17470994e-07,\n       1.62186712e-04, 4.80881863e-05, 8.00260808e-04, 1.15718798e-07,\n       1.36619889e-07, 1.96555516e-06, 1.09494349e-05, 6.01174222e-08,\n       1.25075573e-07, 1.95533843e-07, 3.03061995e-07, 1.39768929e-07,\n       8.00641737e-06, 1.59213164e-06, 1.53417914e-05, 9.97922871e-06,\n       7.51938887e-06, 6.27568988e-06, 6.11166627e-07, 3.21144798e-05,\n       2.30226505e-07, 4.73988272e-04, 3.42470159e-08, 1.13897804e-05,\n       1.34282440e-04, 1.84428586e-06, 2.90087542e-07, 9.15747296e-06,\n       4.92604295e-06, 2.72996522e-06, 1.43825707e-06, 2.16673448e-06,\n       9.44141476e-08, 1.81387918e-06, 1.48026511e-05, 1.06958832e-05,\n       9.35391745e-06, 5.77261012e-08, 1.37634834e-05, 2.71323981e-04,\n       7.75316806e-08, 1.85840181e-04, 1.02216529e-06, 1.21507435e-06,\n       1.70111434e-06, 2.76617158e-07, 6.72527949e-06, 1.54229940e-06,\n       1.41599821e-06, 1.01328556e-06, 2.52412246e-05, 3.37666188e-06,\n       7.23541962e-05, 1.53535940e-08, 1.52860139e-07, 2.97889216e-07,\n       6.46785679e-07, 1.10856001e-06, 4.98448230e-07, 2.81333087e-07,\n       2.81748471e-05, 3.26378228e-07, 6.18223203e-06, 4.74636408e-06,\n       5.56017312e-07, 2.72702232e-06, 1.07234278e-07, 2.04276759e-07,\n       1.46386310e-06, 4.73311097e-08, 2.36653887e-06, 3.50475148e-07,\n       8.11493521e-08, 1.69434415e-07, 3.08825491e-07, 1.36081758e-06,\n       4.58087634e-05, 3.66826413e-07, 1.80790721e-06, 1.62367996e-05,\n       1.91876370e-06, 1.33193237e-06, 1.89858014e-07, 1.72515247e-05,\n       2.20131551e-04, 3.40483695e-08, 1.41141572e-06, 3.17273880e-05,\n       2.86227106e-07, 4.70493660e-07, 3.35305174e-07, 6.18929263e-08,\n       6.77019329e-07, 1.89915693e-06, 1.13638166e-07, 7.16401871e-07,\n       4.47204548e-06, 6.50902757e-06, 1.31395296e-04, 1.12996034e-07,\n       5.75059903e-06, 8.08285949e-06, 1.00234856e-05, 5.22243790e-05,\n       1.37149311e-06, 8.61696435e-07, 1.72534164e-05, 5.08184276e-05,\n       3.07050811e-07, 2.19296641e-03, 2.62390640e-05, 1.82122687e-06,\n       1.57364648e-05, 5.42968155e-06, 2.63521372e-07, 5.56158966e-07,\n       1.80554579e-07, 2.91531942e-05, 5.19655373e-07, 2.40758368e-07,\n       1.82489550e-03, 8.28528130e-07, 1.51563950e-06, 1.34676670e-08,\n       7.46758542e-06, 1.15134237e-04, 2.61182382e-08, 6.97829819e-07,\n       8.65901086e-07, 2.67833087e-07, 1.35427297e-06, 1.49241860e-05,\n       4.14931293e-07, 7.28771847e-05, 4.61258850e-07, 2.71573917e-05,\n       1.69848104e-03, 3.05800386e-05, 2.88569680e-07, 8.54300044e-04,\n       2.48388062e-07, 6.67643735e-06, 3.01167731e-08, 8.66611936e-06,\n       1.71162293e-03, 9.85645602e-05, 1.39914046e-03, 2.71690848e-08,\n       3.65475580e-06, 3.75784275e-08, 8.02191209e-07, 1.23640018e-06,\n       9.54144980e-07, 5.28380667e-07, 3.94977360e-06, 3.23041149e-06,\n       9.14034099e-05, 4.35649163e-05, 1.01663427e-05, 8.48441516e-07,\n       1.74911406e-07, 8.55424176e-08, 8.23286791e-06, 8.68593692e-04,\n       2.81512627e-07, 4.02873255e-08, 1.82666078e-08, 2.56378485e-06,\n       6.53835305e-05, 7.42083590e-04, 3.61798411e-05, 8.36638628e-06,\n       4.86934459e-06, 1.54088903e-03, 6.90186716e-05, 3.39453004e-06,\n       1.52870655e-07, 1.17912727e-07, 1.52917750e-07, 2.26969078e-07,\n       3.93216396e-07, 4.25554049e-07, 2.52778648e-07, 3.33113945e-07,\n       2.38561165e-06, 2.41636371e-07, 3.34273409e-08, 1.21015205e-07,\n       1.36697821e-07, 1.04883959e-07, 7.58559437e-08, 9.17545435e-08,\n       6.48123091e-07, 2.63734563e-07, 1.88459765e-07, 5.44224150e-08,\n       1.89884616e-07, 2.64440629e-08, 2.54756827e-07, 5.18354113e-07,\n       7.84733288e-07, 2.14700933e-07, 9.20629418e-07, 1.25542181e-06,\n       6.21227002e-07, 8.52296012e-07, 2.57921158e-07, 8.94824908e-08,\n       7.07511134e-08, 3.69745590e-06, 2.35872494e-06, 3.24751653e-07,\n       2.38422302e-07, 6.13753514e-07, 8.46861155e-07, 1.24351618e-05,\n       5.15612328e-07, 1.65321268e-07, 3.78414057e-07, 4.06713561e-08,\n       3.16607384e-07, 2.24534453e-08, 2.26040456e-07, 5.30576472e-06,\n       3.93846342e-08, 2.05881770e-06, 1.38403252e-07, 9.08526829e-07,\n       1.11538768e-07, 8.02688646e-07, 3.48416461e-06, 1.21096591e-07,\n       5.70200427e-07, 7.54340661e-08, 2.97615907e-06, 2.68589595e-08,\n       6.38429128e-07, 2.49139902e-07, 6.84531827e-08, 2.88778801e-06,\n       4.44204261e-07, 4.85821943e-07, 3.24110397e-06, 3.60254887e-07,\n       3.54508359e-07, 1.57357150e-07, 2.29814852e-08, 8.98909491e-07,\n       6.93708557e-07, 2.47878120e-07, 1.51536494e-06, 9.71208394e-08],\n      dtype=float32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][1]\n",
    "# type(dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "from torchvision.transforms import ToTensor\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 3-dimensional input of size [3, 200, 200] instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-af92fdaeef6c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvgg16\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mToTensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0ma\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\vgg.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mavgpool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    422\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 423\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    424\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight)\u001B[0m\n\u001B[0;32m    417\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    418\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m--> 419\u001B[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001B[0m\u001B[0;32m    420\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 3-dimensional input of size [3, 200, 200] instead"
     ]
    }
   ],
   "source": [
    "a = vgg16()\n",
    "f = ToTensor()\n",
    "a(f(dataset[0][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 200, 200])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(dataset[0][0]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n ReLU(inplace=True),\n MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.features.children())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}